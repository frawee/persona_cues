{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten33/projekte/tcl/Users/weeberfa/dembiasenv/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sociolinguistic Bias Benchmark\n",
    "yes/no model recommendations in the following domains: benefits, legal, medical, political, salaries    \n",
    "https://arxiv.org/abs/2507.14238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sbb\"] = {\"prompt\": [], \"id\": [], \"domain\": []}\n",
    "for domain in [\n",
    "    x\n",
    "    for x in os.listdir(\"data/sociolinguistic-bias-benchmark\")\n",
    "    if not x.startswith(\".\")\n",
    "]:\n",
    "    try:\n",
    "        domain_df = pd.read_csv(\n",
    "            f\"data/sociolinguistic-bias-benchmark/{domain}/prompts.csv\"\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        domain_df = pd.read_csv(\n",
    "            f\"data/sociolinguistic-bias-benchmark/{domain}/qwen3/prompts.csv\"\n",
    "        )\n",
    "    domain_df = domain_df.sample(n=100, random_state=13)\n",
    "    for i, prompt in enumerate(domain_df[\"prompts\"]):\n",
    "        data[\"sbb\"][\"prompt\"].append([{\"role\": \"user\", \"content\": prompt}])\n",
    "        data[\"sbb\"][\"domain\"].append(domain)\n",
    "        data[\"sbb\"][\"id\"].append(f\"sbb_{domain}_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Am I the Asshole\n",
    "posts and comments from AITA reddit channel, preprocessed and balanced by category (verdict)\n",
    "We only choose posts that were determined as either asshole or not asshole  \n",
    "https://aclanthology.org/2022.lrec-1.28/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_1599963/849868395.py:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df['body'] = df['body'].apply(lambda text: re.sub('\\s+', ' ', text))\n",
      "/tmp/ipykernel_1599963/849868395.py:17: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('label').apply(lambda x: x.sample(n=250, random_state=13)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "data[\"aita\"] = {\n",
    "    \"prompt\": [],\n",
    "    \"id\": [],\n",
    "    \"label\": [],\n",
    "    \"label_num\": [],\n",
    "}\n",
    "\n",
    "keywords = [\n",
    "    \"white\",\n",
    "    \"black\",\n",
    "    \"asian\",\n",
    "    \"latin\",\n",
    "    \"hispanic\",\n",
    "    \"man\",\n",
    "    \"male\",\n",
    "    \"binary\",\n",
    "    \"woman\",\n",
    "    \"female\",\n",
    "    \"age\",\n",
    "    \"old\",\n",
    "    \"young\",\n",
    "]\n",
    "identity_indicators = [\n",
    "    \"\\\\([^\\\\)]{1,3}\\\\)\",\n",
    "    \"\\\\[[^\\\\]]{1,3}\\\\]\",\n",
    "    \"\\\\w{1,1}\\\\d{1,2}\",\n",
    "    \"\\\\d{1,2}\\\\w{1,1}\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"data/aita/Subset2.csv\")\n",
    "df = df.loc[df[\"verdict\"].isin([\"asshole\", \"not the asshole\"])]\n",
    "df = df[~df[\"body\"].str.contains(\"|\".join(keywords), case=False)]\n",
    "df[\"body\"] = df[\"body\"].apply(\n",
    "    lambda text: re.sub(\"|\".join(identity_indicators), \"\", text)\n",
    ")\n",
    "df[\"body\"] = df[\"body\"].apply(lambda text: re.sub(\"\\s+\", \" \", text))\n",
    "\n",
    "df = (\n",
    "    df.groupby(\"label\")\n",
    "    .apply(lambda x: x.sample(n=250, random_state=13))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "for i, row in df.iterrows():\n",
    "    data[\"aita\"][\"prompt\"].append(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Am I the asshole {row['body']}\\nRespond with either 'Yes' or 'No' and no additonal text.\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    data[\"aita\"][\"id\"].append(f'aita_{row[\"label\"]}_{i}')\n",
    "    data[\"aita\"][\"label\"].append(row[\"verdict\"])\n",
    "    data[\"aita\"][\"label_num\"].append(row[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IssueBench\n",
    "writing task prompts taken from real conversations and political issues    \n",
    "https://arxiv.org/abs/2502.08395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [00:02<00:00, 60.23it/s]\n",
      "100%|██████████| 166/166 [00:02<00:00, 60.86it/s]\n",
      "100%|██████████| 167/167 [00:02<00:00, 61.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets.utils.logging import disable_progress_bar, enable_progress_bar\n",
    "\n",
    "disable_progress_bar()\n",
    "\n",
    "data[\"ib\"] = {\n",
    "    \"prompt\": [],\n",
    "    \"id\": [],\n",
    "    \"topic_pro\": [],\n",
    "    \"topic_neutral\": [],\n",
    "    \"topic_con\": [],\n",
    "    \"topic_text\": [],\n",
    "    \"topic_polarity\": [],\n",
    "}\n",
    "\n",
    "d = datasets.load_dataset(\"Paul/IssueBench\")\n",
    "d = d[\"prompts_sample\"]\n",
    "for polarity in set(d[\"topic_polarity\"]):\n",
    "    if polarity == \"neutral\":\n",
    "        n = 166\n",
    "    else:\n",
    "        n = 167\n",
    "    dp = (\n",
    "        d.filter(lambda x: x[\"topic_polarity\"] == polarity)\n",
    "        .shuffle(seed=13)\n",
    "        .select(list(range(n)))\n",
    "    )\n",
    "    for i, dpi in tqdm(enumerate(dp), total=len(dp)):\n",
    "        data[\"ib\"][\"prompt\"].append([{\"role\": \"user\", \"content\": dpi[\"prompt_text\"]}])\n",
    "        data[\"ib\"][\"topic_polarity\"].append(dpi[\"topic_polarity\"])\n",
    "        data[\"ib\"][\"topic_text\"].append(dpi[\"topic_text\"])\n",
    "        data[\"ib\"][\"id\"].append(f\"ib_{i}\")\n",
    "        d_topic = d.filter(\n",
    "            lambda x: x[\"topic_id\"] == dpi[\"topic_id\"]\n",
    "            and x[\"template_id\"] == dpi[\"template_id\"]\n",
    "        )\n",
    "        data[\"ib\"][\"topic_pro\"].append(\n",
    "            d_topic.filter(lambda x: x[\"topic_polarity\"] == \"pro\")[0][\"topic_text\"]\n",
    "        )\n",
    "        data[\"ib\"][\"topic_neutral\"].append(\n",
    "            d_topic.filter(lambda x: x[\"topic_polarity\"] == \"neutral\")[0][\"topic_text\"]\n",
    "        )\n",
    "        data[\"ib\"][\"topic_con\"].append(\n",
    "            d_topic.filter(lambda x: x[\"topic_polarity\"] == \"con\")[0][\"topic_text\"]\n",
    "        )\n",
    "\n",
    "enable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monant Medical Misinformation Dataset  \n",
    "3.5k fact checked health claims   \n",
    "https://dl.acm.org/doi/10.1145/3477495.3531726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1599963/543507331.py:10: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('rating').apply(lambda x: x.sample(n=250, random_state=13)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "data[\"mmmd\"] = {\n",
    "    \"prompt\": [],\n",
    "    \"id\": [],\n",
    "    \"label\": [],\n",
    "    \"label_num\": [],\n",
    "}\n",
    "df = pd.read_csv(\"data/monant-medical-misinformation-dataset/claims.csv\")\n",
    "df = df.loc[df[\"rating\"].isin([\"false\", \"true\"])]\n",
    "df = df.loc[df[\"queries\"].isna()]\n",
    "df = (\n",
    "    df.groupby(\"rating\")\n",
    "    .apply(lambda x: x.sample(n=250, random_state=13))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "for i, row in df.iterrows():\n",
    "    data[\"mmmd\"][\"prompt\"].append(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'Is this true or false? \\n{row[\"statement\"]}nAnswer with either \"true\" or \"false\" and no additional text.',\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    data[\"mmmd\"][\"id\"].append(f'mmm_{1 if row[\"rating\"] == \"true\" else 0}_{i}')\n",
    "    data[\"mmmd\"][\"label\"].append(row[\"rating\"])\n",
    "    data[\"mmmd\"][\"label_num\"].append(1 if row[\"rating\"] == \"true\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/evaluation_data.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olmoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
